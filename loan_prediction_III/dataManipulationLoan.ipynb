#! /usr/bin/python3.5.2

#rename pandas and other modules as pd,np (alias) 


import pandas as pd
# for mathematical calculation
import numpy as np   
# for plotting 2D graphs
import matplotlib.pyplot as plt
# for statistic data visualization
import seaborn as sns

import statistics as stat

# Series
s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])
s.str.lower()
s.str.upper()
s.str.len()
# 
idx.str.strip()
idx.str.lstrip()
idx.str.rstrip()

#Methods like split return a Series of lists:
s2 = pd.Series(['a_b_c', 'c_d_e', np.nan, 'f_g_h'])
s2.str.split('_')
s2.str.split('_').str.get(1)
s2.str.split('_').str[1]

#DataFrame using expand.
s2.str.split('_', expand=True)
# limit the number of splits:
s2.str.split('_', expand=True, n=1)

#rsplit is similar to split except it works in the reverse direction, i.e., 
#from the end of the string to the beginning of  the string:
s2.str.rsplit('_', expand=True, n=1)

#replace by default replaces regular expressions:
s3 = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca','', np.nan, 'CABA', 'dog', 'cat'])
s3.str.replace('^.a|dog', 'XX-XX ', case=False)

#load .csv file using function "read_csv()" in pandas 
# use "skiprow=1" argument if column names indexed i.e. 1st observation 0 and so on..

loan_train_dataset=pd.read_csv('train_u6lujuX_CVtuZ9i.csv')

# Copy of original train and test dataset
train_original=loan_train_dataset.copy();
# print whole dataset

print(loan_train_dataset);

# print first some rows alongwith all columns in dataset using function ".head("<number_of_rows> as argument)

print(loan_train_dataset.head(5))

# print last some rows alongwith all columns in dataset using function ".tail("<number_of_rows> as argument)

print(loan_train_dataset.tail(5))

# print data type of any column

print(loan_train_dataset['Gender'].dtype)

# Missing value imputation

loan_train_data_missing=pd.read_csv('train_u6lujuX_CVtuZ9i.csv',na_values=['no_info','.'])
print(loan_train_data_missing.head(25))

# select specific coulumns

print(loan_train_data_missing[['Gender','Married']])

# Filter for specific values in your dataframe.Here in column where gender==Male condition True and all such rows fetched.

print(loan_train_data_missing[loan_train_data_missing.Gender=='Male'])

# functions can be used after each other

print(loan_train_data_missing.head(5)[['Gender']])
print(loan_train_data_missing[['Gender']].head(5))

###### Aggregation and Grouping ##############
#column name & number of rows

print(loan_train_data_missing.count())

# select particular column and count number of rows

print(loan_train_data_missing.Gender.count())

# column name and number of rows 
print(loan_train_data_missing[['Gender']].count())

# sum min max mean median

print(loan_train_data_missing.LoanAmount.sum())
print(loan_train_data_missing[['LoanAmount']].sum())
print(loan_train_data_missing[['LoanAmount']].min())
print(loan_train_data_missing[['LoanAmount']].max())
print(loan_train_data_missing[['LoanAmount']].mean())
print(loan_train_data_missing[['LoanAmount']].median())

# "Groupby"function on "gender" column  and return mean of each column as per male and female
print(loan_train_data_missing.groupby('Gender').mean())

# mean of individual column groupby gender
print(loan_train_data_missing.groupby('Gender').mean()[['LoanAmount']])

############### Data formatting methods-sort,merge,concat,reset_index,fillna########

# Pandas Merge (inner join by default)  Like SQL Join ,works only when common column in both dataset
# joins works horizontally i.e. they combine two sets (dataframes) column wise 

first_loan_dataset=pd.DataFrame(loan_train_data_missing[['Loan_ID','LoanAmount','Loan_Amount_Term']].head(25))
print(first_loan_dataset)
second_loan_dataset=pd.DataFrame(loan_train_data_missing[['Loan_ID','Credit_History','Property_Area']].head(25))
print(second_loan_dataset)
third_loan_dataset=pd.DataFrame(loan_train_data_missing[['Loan_ID','Gender','Married','Dependents']])
print(third_loan_dataset)
fourth_loan_dataset=pd.DataFrame(loan_train_data_missing[['Gender','Married','Dependents']].head(25))
print(fourth_loan_dataset)

# inner join=values found in both tables (common)
print(first_loan_dataset.merge(second_loan_dataset))

#outer join=all values even some found in only one table
print(second_loan_dataset.merge(third_loan_dataset,how='outer'))

#left join=all values from left and common in both
print(second_loan_dataset.merge(third_loan_dataset,how='left'))

#right join=all values in right and common in both
print(second_loan_dataset.merge(third_loan_dataset,how='right'))

#NO COMMON COLUMN FOUND,where to apply join-use right_on,left_on arguments to join both dataset
print(first_loan_dataset.merge(fourth_loan_dataset,how='left',left_on='Loan_ID',right_on='Dependents'))

#Like its sibling function on ndarrays, numpy.concatenate, pandas.concat takes a list or dict of homogeneously-typed objects # and concatenates them with some configurable handling of “what to do with the other axes”:
pd.concat(objs,axis=0,join='outer',join_axes=None,ignore_index=False,keys=None,levels=None,names=None,verify_integrity=False,copy=True)

#sorting by default ascending
print(loan_train_data_missing.sort_values(by=['Gender']))
#sorting, by default ascending,you can use multiple arguments in 'by'
print(loan_train_data_missing.sort_values(by=['LoanAmount'],ascending=False))

#'reset_index' method ==After data transformation eg. after sorting we have to reset index
print(loan_train_data_missing.sort_values(by=['LoanAmount'],ascending=False).reset_index())

# In reset_index method our old indices are preserved,to drop it use drop argument as
print(loan_train_data_missing.sort_values(by=['LoanAmount'],ascending=False).reset_index(drop=True))

# Impute missing values (NaN) with fillna method
print(first_loan_dataset.merge(fourth_loan_dataset,how='left',left_on='Loan_ID',right_on='Dependents').fillna('unknown'))


